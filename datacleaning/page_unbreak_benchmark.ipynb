{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQI7wwDNSBMW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zTyFSUgDUyEW"
      },
      "outputs": [],
      "source": [
        "file = open(\"/content/hvd.hn6k5w.norm.txt\", \"r\") # replace filename\n",
        "doc = file.read()\n",
        "file.close()\n",
        "# takes the sentence before and after a <pb>\n",
        "page_bounds = re.findall(r'[.!?]+[^!?.]*<pb>[^!?.]*[.!?]+', doc)\n",
        "# gets rid of the end punctuation(s) at the start of the text that the above regex captures\n",
        "page_bounds_new = [re.sub(r'^[.!?]+', '', text) for text in page_bounds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "pwnExU6Ztfam",
        "outputId": "6715d5e0-16c2-4947-dbfa-e7fd2e4a555e"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "model = LLM(\"PleIAs/OCRonos\", dtype=\"float16\", max_model_len=8128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxriIpmuI3ml"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# OCRonos helper function, taken from app.py in the OCRonos app in huggingface\n",
        "def correct_ocr(user_message):\n",
        "  sampling_params = SamplingParams(temperature=0.9, top_p=0.95, max_tokens=4000, presence_penalty=0, stop=[\"#END#\"])\n",
        "  prompt_template = f\"### TEXT ###\\n{user_message}\\n\\n### CORRECTION ###\\n\"\n",
        "  prompts = [prompt_template]\n",
        "  outputs = model.generate(prompts, sampling_params, use_tqdm=False)\n",
        "  generated_text = outputs[0].outputs[0].text\n",
        "  return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC44LJ-1xLrb"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "for i in tqdm(range(len(page_bounds_new))):\n",
        "  pb = page_bounds_new[i]\n",
        "  result = correct_ocr(pb)\n",
        "  preds.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzqkLXgU_U1s"
      },
      "outputs": [],
      "source": [
        "# # save to csv\n",
        "# df2 = pd.DataFrame(preds)\n",
        "# df2.to_csv(\"harvard_preds2.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
